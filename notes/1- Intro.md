https://huggingface.co/learn/llm-course/chapter1/1
* Hugging Face ecosystem libraries for NLP:
	* Transformers
	* Datasets
	* Tokenizers
	* Accelerate
* NLP - broader field aimed at making computers understand, interpret and generate human language. Used for sentiment analysis, NER and machine translation.
* LLMs - subset of NLP models. 
* What we will learn:
	* Transformer library - using a model from Hugging Face Hub, fine-tuning it on a dataset, sharing the results on Hub.
	* Datasets library 
	* Tokenizers library
	* Classic NLP tasks
	* Build and share demos of model on Hub
	* Optimizing for production - fine-tuning, curating high-quality datasets, building reasoning models.
* https://pytorch.org/
* Pre-requisite course - https://course.fast.ai/
* Next step course - NLP Specialization from Deeplearning.ai - to learn more about traditional NLP models like naive Bayes and  LSTMs.
* 
* 